# Phase 9: ì‹¤ì œ AI í†µí•© êµ¬í˜„ ê°€ì´ë“œ

## ğŸ¤– OpenAI API ì™„ì „ í†µí•© ê³„íš

### 9.1 OpenAI API ì„¤ì • ë° êµ¬ì„±

#### ë‹¨ê³„ 1: API í‚¤ ì„¤ì •
```bash
# .env íŒŒì¼ì— ì¶”ê°€
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4
OPENAI_MAX_TOKENS=4000
OPENAI_TEMPERATURE=0.7
OPENAI_TIMEOUT=30000

# ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
OPENAI_DAILY_LIMIT=100000  # ì¼ì¼ í† í° í•œë„
OPENAI_COST_ALERT=50       # ë¹„ìš© ì•Œë¦¼ ì„ê³„ê°’ ($)
```

#### ë‹¨ê³„ 2: OpenAI SDK ì—…ê·¸ë ˆì´ë“œ
```bash
npm install openai@latest
npm install node-cache        # ì‘ë‹µ ìºì‹±ìš©
npm install tiktoken         # í† í° ê³„ì‚°ìš©
```

#### ë‹¨ê³„ 3: í–¥ìƒëœ AIService êµ¬í˜„

**src/modules/ai/EnhancedAIService.js**:
```javascript
import OpenAI from 'openai';
import NodeCache from 'node-cache';
import { encoding_for_model } from 'tiktoken';
import { DatabaseService } from '../../services/DatabaseService.js';

export class EnhancedAIService {
  constructor() {
    this.openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY
    });
    
    this.cache = new NodeCache({ stdTTL: 3600 }); // 1ì‹œê°„ ìºì‹œ
    this.db = new DatabaseService();
    this.encoder = encoding_for_model(process.env.OPENAI_MODEL || 'gpt-4');
    
    this.usage = {
      totalTokens: 0,
      totalCost: 0,
      requestCount: 0
    };
    
    this.initializeUsageTracking();
  }

  async generateCode(prompt, options = {}) {
    try {
      const {
        language = 'javascript',
        framework = '',
        style = 'modern',
        includeComments = true,
        includeTests = false
      } = options;

      // ìºì‹œ í™•ì¸
      const cacheKey = this.generateCacheKey('code', { prompt, language, framework });
      const cached = this.cache.get(cacheKey);
      if (cached) return cached;

      // í”„ë¡¬í”„íŠ¸ ìµœì í™”
      const optimizedPrompt = this.buildCodeGenerationPrompt(
        prompt, language, framework, style, includeComments, includeTests
      );

      // OpenAI API í˜¸ì¶œ
      const response = await this.callOpenAI(optimizedPrompt, {
        temperature: 0.2, // ì½”ë“œ ìƒì„±ì€ ë‚®ì€ temperature
        max_tokens: parseInt(process.env.OPENAI_MAX_TOKENS)
      });

      // ê²°ê³¼ ì²˜ë¦¬ ë° ê²€ì¦
      const result = this.processCodeResponse(response);
      
      // ìºì‹œ ì €ì¥
      this.cache.set(cacheKey, result);
      
      // ì‚¬ìš©ëŸ‰ ì¶”ì 
      await this.trackUsage('code_generation', response.usage);

      return result;

    } catch (error) {
      console.error('ì½”ë“œ ìƒì„± ì˜¤ë¥˜:', error);
      throw new Error(`ì½”ë“œ ìƒì„± ì‹¤íŒ¨: ${error.message}`);
    }
  }

  async reviewCode(code, options = {}) {
    try {
      const {
        language = 'javascript',
        focusAreas = ['performance', 'security', 'maintainability'],
        severity = 'all'
      } = options;

      const cacheKey = this.generateCacheKey('review', { code: this.hashCode(code), language });
      const cached = this.cache.get(cacheKey);
      if (cached) return cached;

      const reviewPrompt = this.buildCodeReviewPrompt(code, language, focusAreas, severity);
      
      const response = await this.callOpenAI(reviewPrompt, {
        temperature: 0.1, // ì½”ë“œ ë¦¬ë·°ëŠ” ì¼ê´€ì„± ì¤‘ìš”
        max_tokens: 2000
      });

      const result = this.processReviewResponse(response);
      
      this.cache.set(cacheKey, result);
      await this.trackUsage('code_review', response.usage);

      return result;

    } catch (error) {
      console.error('ì½”ë“œ ë¦¬ë·° ì˜¤ë¥˜:', error);
      throw new Error(`ì½”ë“œ ë¦¬ë·° ì‹¤íŒ¨: ${error.message}`);
    }
  }

  async generateTests(code, options = {}) {
    try {
      const {
        language = 'javascript',
        framework = 'jest',
        coverage = 'comprehensive',
        testTypes = ['unit', 'integration']
      } = options;

      const cacheKey = this.generateCacheKey('tests', { 
        code: this.hashCode(code), language, framework 
      });
      const cached = this.cache.get(cacheKey);
      if (cached) return cached;

      const testPrompt = this.buildTestGenerationPrompt(
        code, language, framework, coverage, testTypes
      );

      const response = await this.callOpenAI(testPrompt, {
        temperature: 0.3,
        max_tokens: 3000
      });

      const result = this.processTestResponse(response);
      
      this.cache.set(cacheKey, result);
      await this.trackUsage('test_generation', response.usage);

      return result;

    } catch (error) {
      console.error('í…ŒìŠ¤íŠ¸ ìƒì„± ì˜¤ë¥˜:', error);
      throw new Error(`í…ŒìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: ${error.message}`);
    }
  }

  async chatAssistant(message, context = {}) {
    try {
      const {
        conversationId = null,
        projectContext = {},
        codeContext = null
      } = context;

      // ëŒ€í™” ê¸°ë¡ ì¡°íšŒ
      let conversationHistory = [];
      if (conversationId) {
        conversationHistory = await this.getConversationHistory(conversationId);
      }

      const chatPrompt = this.buildChatPrompt(
        message, conversationHistory, projectContext, codeContext
      );

      const response = await this.callOpenAI(chatPrompt, {
        temperature: 0.7, // ëŒ€í™”ëŠ” ìì—°ìŠ¤ëŸ½ê²Œ
        max_tokens: 1500
      });

      const result = this.processChatResponse(response);
      
      // ëŒ€í™” ê¸°ë¡ ì €ì¥
      if (conversationId) {
        await this.saveConversationTurn(conversationId, message, result.response);
      }

      await this.trackUsage('chat_assistant', response.usage);

      return result;

    } catch (error) {
      console.error('AI ì–´ì‹œìŠ¤í„´íŠ¸ ì˜¤ë¥˜:', error);
      throw new Error(`AI ì–´ì‹œìŠ¤í„´íŠ¸ ì‹¤íŒ¨: ${error.message}`);
    }
  }

  // í”„ë¡¬í”„íŠ¸ ë¹Œë” ë©”ì„œë“œë“¤
  buildCodeGenerationPrompt(prompt, language, framework, style, includeComments, includeTests) {
    return `
ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œìì…ë‹ˆë‹¤. ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì— ë”°ë¼ ê³ í’ˆì§ˆì˜ ${language} ì½”ë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

ìš”êµ¬ì‚¬í•­: ${prompt}

ê°œë°œ ì¡°ê±´:
- ì–¸ì–´: ${language}
- í”„ë ˆì„ì›Œí¬: ${framework || 'ì—†ìŒ'}
- ìŠ¤íƒ€ì¼: ${style}
- ì£¼ì„ í¬í•¨: ${includeComments ? 'ì˜ˆ' : 'ì•„ë‹ˆì˜¤'}
- í…ŒìŠ¤íŠ¸ í¬í•¨: ${includeTests ? 'ì˜ˆ' : 'ì•„ë‹ˆì˜¤'}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
\`\`\`json
{
  "code": "ìƒì„±ëœ ì½”ë“œ",
  "explanation": "ì½”ë“œ ì„¤ëª…",
  "dependencies": ["í•„ìš”í•œ ì˜ì¡´ì„±"],
  "usage_example": "ì‚¬ìš© ì˜ˆì‹œ",
  "notes": ["ì¶”ê°€ ì°¸ê³ ì‚¬í•­"]
}
\`\`\`

ëª¨ë²” ì‚¬ë¡€ë¥¼ ë”°ë¥´ê³ , ê°€ë…ì„±ê³¼ ìœ ì§€ë³´ìˆ˜ì„±ì„ ì¤‘ì‹œí•˜ì—¬ ì‘ì„±í•´ì£¼ì„¸ìš”.
`;
  }

  buildCodeReviewPrompt(code, language, focusAreas, severity) {
    return `
ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤. ë‹¤ìŒ ${language} ì½”ë“œë¥¼ ì „ë¬¸ì ìœ¼ë¡œ ë¦¬ë·°í•´ì£¼ì„¸ìš”.

ê²€í†  ì½”ë“œ:
\`\`\`${language}
${code}
\`\`\`

ê²€í†  ì¤‘ì  ì‚¬í•­: ${focusAreas.join(', ')}
ì‹¬ê°ë„ í•„í„°: ${severity}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
\`\`\`json
{
  "overall_score": 85,
  "issues": [
    {
      "type": "performance|security|maintainability|bug",
      "severity": "high|medium|low",
      "line": 10,
      "message": "ë¬¸ì œ ì„¤ëª…",
      "suggestion": "ê°œì„  ì œì•ˆ"
    }
  ],
  "strengths": ["ì½”ë“œì˜ ì¥ì ë“¤"],
  "improvements": ["ê°œì„  ì œì•ˆë“¤"],
  "best_practices": ["ì ìš©ëœ ëª¨ë²” ì‚¬ë¡€ë“¤"]
}
\`\`\`

ì •í™•í•˜ê³  ê±´ì„¤ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”.
`;
  }

  buildTestGenerationPrompt(code, language, framework, coverage, testTypes) {
    return `
ì „ë¬¸ í…ŒìŠ¤íŠ¸ ì—”ì§€ë‹ˆì–´ë¡œì„œ ë‹¤ìŒ ${language} ì½”ë“œì— ëŒ€í•œ ${framework} í…ŒìŠ¤íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

ëŒ€ìƒ ì½”ë“œ:
\`\`\`${language}
${code}
\`\`\`

í…ŒìŠ¤íŠ¸ ìš”êµ¬ì‚¬í•­:
- í”„ë ˆì„ì›Œí¬: ${framework}
- ì»¤ë²„ë¦¬ì§€: ${coverage}
- í…ŒìŠ¤íŠ¸ ìœ í˜•: ${testTypes.join(', ')}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
\`\`\`json
{
  "test_code": "ìƒì„±ëœ í…ŒìŠ¤íŠ¸ ì½”ë“œ",
  "test_cases": [
    {
      "name": "í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì´ë¦„",
      "description": "í…ŒìŠ¤íŠ¸ ì„¤ëª…",
      "type": "unit|integration|e2e"
    }
  ],
  "coverage_estimate": 95,
  "setup_instructions": "í…ŒìŠ¤íŠ¸ ì„¤ì • ë°©ë²•",
  "dependencies": ["í…ŒìŠ¤íŠ¸ ì˜ì¡´ì„±"]
}
\`\`\`

í¬ê´„ì ì´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í…ŒìŠ¤íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
`;
  }

  // OpenAI API í˜¸ì¶œ ë˜í¼
  async callOpenAI(prompt, options = {}) {
    const startTime = Date.now();
    
    try {
      // í† í° ìˆ˜ ê³„ì‚°
      const tokens = this.countTokens(prompt);
      
      // ì¼ì¼ í•œë„ í™•ì¸
      await this.checkDailyLimit(tokens);

      const response = await this.openai.chat.completions.create({
        model: process.env.OPENAI_MODEL || 'gpt-4',
        messages: [
          {
            role: 'system',
            content: 'You are a professional software developer assistant.'
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        temperature: options.temperature || 0.7,
        max_tokens: options.max_tokens || 2000,
        timeout: parseInt(process.env.OPENAI_TIMEOUT || '30000')
      });

      const duration = Date.now() - startTime;
      
      // ì‘ë‹µ ë¡œê¹…
      console.log(`OpenAI API í˜¸ì¶œ ì™„ë£Œ: ${duration}ms, í† í°: ${response.usage.total_tokens}`);

      return response;

    } catch (error) {
      const duration = Date.now() - startTime;
      console.error(`OpenAI API ì˜¤ë¥˜: ${duration}ms, ${error.message}`);
      throw error;
    }
  }

  // ì‚¬ìš©ëŸ‰ ì¶”ì 
  async trackUsage(operation, usage) {
    this.usage.totalTokens += usage.total_tokens;
    this.usage.requestCount++;
    
    // GPT-4 ìš”ê¸ˆ ê³„ì‚° (ëŒ€ëµì )
    const cost = (usage.prompt_tokens * 0.03 + usage.completion_tokens * 0.06) / 1000;
    this.usage.totalCost += cost;

    // ë°ì´í„°ë² ì´ìŠ¤ì— ì‚¬ìš©ëŸ‰ ê¸°ë¡
    const usageRecord = {
      id: `usage_${Date.now()}`,
      operation,
      model: process.env.OPENAI_MODEL,
      prompt_tokens: usage.prompt_tokens,
      completion_tokens: usage.completion_tokens,
      total_tokens: usage.total_tokens,
      estimated_cost: cost,
      created_at: new Date().toISOString()
    };

    await this.db.saveAIUsage(usageRecord);

    // ë¹„ìš© ì•Œë¦¼
    if (this.usage.totalCost > parseInt(process.env.OPENAI_COST_ALERT || '50')) {
      console.warn(`âš ï¸ OpenAI ì‚¬ìš© ë¹„ìš©ì´ $${this.usage.totalCost.toFixed(2)}ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤!`);
    }
  }

  // í† í° ê³„ì‚°
  countTokens(text) {
    return this.encoder.encode(text).length;
  }

  // ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
  generateCacheKey(type, params) {
    return `${type}_${JSON.stringify(params)}`;
  }

  hashCode(str) {
    let hash = 0;
    for (let i = 0; i < str.length; i++) {
      const char = str.charCodeAt(i);
      hash = ((hash << 5) - hash) + char;
      hash = hash & hash; // 32bit integer ë³€í™˜
    }
    return hash;
  }

  // ì‚¬ìš©ëŸ‰ í†µê³„
  getUsageStats() {
    return {
      ...this.usage,
      averageCostPerRequest: this.usage.requestCount > 0 
        ? this.usage.totalCost / this.usage.requestCount 
        : 0
    };
  }
}
```

### 9.2 ê¸°ì¡´ ëª¨ë“ˆ ì—…ê·¸ë ˆì´ë“œ

#### CodeGenerator ì—…ê·¸ë ˆì´ë“œ
```javascript
// src/modules/ai/CodeGenerator.js ì—…ë°ì´íŠ¸
import { EnhancedAIService } from './EnhancedAIService.js';

export class CodeGenerator {
  constructor() {
    this.aiService = new EnhancedAIService(); // ì—…ê·¸ë ˆì´ë“œëœ ì„œë¹„ìŠ¤ ì‚¬ìš©
    // ... ê¸°ì¡´ ì½”ë“œ
  }

  async generateCode(prompt, options = {}) {
    // ì‹¤ì œ AI ê¸°ëŠ¥ í™œì„±í™”
    return await this.aiService.generateCode(prompt, options);
  }
}
```

#### CodeReviewService ì—…ê·¸ë ˆì´ë“œ
```javascript
// AI ë¶„ì„ ê°œì„ 
async performAIAnalysis(codeContent, filePath) {
  try {
    const aiReview = await this.aiService.reviewCode(codeContent, {
      language: this.detectLanguage(filePath),
      focusAreas: ['performance', 'security', 'maintainability'],
      severity: 'all'
    });

    return {
      score: aiReview.overall_score,
      insights: aiReview.strengths,
      improvements: aiReview.improvements,
      issues: aiReview.issues
    };
  } catch (error) {
    console.error('AI ë¶„ì„ ì˜¤ë¥˜:', error);
    return { score: 50, insights: ['AI ë¶„ì„ì„ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'] };
  }
}
```

### 9.3 ìƒˆë¡œìš´ AI ì–´ì‹œìŠ¤í„´íŠ¸ ì±„íŒ… ì‹œìŠ¤í…œ

**src/routes/ai-chat.js**:
```javascript
import express from 'express';
import { EnhancedAIService } from '../modules/ai/EnhancedAIService.js';

const router = express.Router();
const aiService = new EnhancedAIService();

// ìƒˆ ëŒ€í™” ì‹œì‘
router.post('/start', async (req, res) => {
  try {
    const conversationId = `conv_${Date.now()}`;
    
    res.json({
      success: true,
      data: {
        conversationId,
        message: 'AI ì–´ì‹œìŠ¤í„´íŠ¸ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?'
      }
    });
  } catch (error) {
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

// ë©”ì‹œì§€ ì „ì†¡
router.post('/message', async (req, res) => {
  try {
    const { message, conversationId, projectContext, codeContext } = req.body;
    
    const response = await aiService.chatAssistant(message, {
      conversationId,
      projectContext,
      codeContext
    });
    
    res.json({
      success: true,
      data: response
    });
  } catch (error) {
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

export default router;
```

### 9.4 ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ

**src/routes/ai-usage.js**:
```javascript
router.get('/stats', async (req, res) => {
  try {
    const stats = aiService.getUsageStats();
    const dailyUsage = await aiService.getDailyUsage();
    
    res.json({
      success: true,
      data: {
        current_session: stats,
        daily_usage: dailyUsage,
        cost_breakdown: {
          today: dailyUsage.cost,
          month: await aiService.getMonthlyUsage(),
          limit: process.env.OPENAI_DAILY_LIMIT
        }
      }
    });
  } catch (error) {
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});
```

### 9.5 êµ¬í˜„ ì¼ì •

#### 1ì¼ì°¨: ê¸°ë³¸ AI í†µí•©
- OpenAI API í‚¤ ì„¤ì •
- EnhancedAIService êµ¬í˜„
- ê¸°ë³¸ ì½”ë“œ ìƒì„± ê¸°ëŠ¥ í™œì„±í™”

#### 2ì¼ì°¨: ê³ ê¸‰ AI ê¸°ëŠ¥
- ì½”ë“œ ë¦¬ë·° AI ë¶„ì„ ê°œì„ 
- í…ŒìŠ¤íŠ¸ ìƒì„± AI í†µí•©
- ì‚¬ìš©ëŸ‰ ì¶”ì  ì‹œìŠ¤í…œ

#### 3ì¼ì°¨: AI ì–´ì‹œìŠ¤í„´íŠ¸ ë° ìµœì í™”
- ì±„íŒ… ì–´ì‹œìŠ¤í„´íŠ¸ êµ¬í˜„
- ìºì‹± ì‹œìŠ¤í…œ ìµœì í™”
- ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ êµ¬ì¶•

ì´ êµ¬í˜„ì„ í†µí•´ ì‹¤ì œ GPT-4ì˜ ê°•ë ¥í•œ AI ëŠ¥ë ¥ì„ í™œìš©í•œ ì™„ì „ ìë™í™”ëœ ê°œë°œ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!
