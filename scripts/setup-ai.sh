#!/bin/bash

# AI ê°œë°œ ì‹œìŠ¤í…œ - AI í†µí•© ì´ˆê¸°í™” ìŠ¤í¬ë¦½íŠ¸
# OpenAI API ì‹¤ì œ í†µí•©ì„ ìœ„í•œ ìžë™ ì„¤ì •

echo "ðŸ¤– AI ì‹œìŠ¤í…œ ì‹¤ì œ í†µí•© ì‹œìž‘..."

# í˜„ìž¬ ë””ë ‰í„°ë¦¬ í™•ì¸
if [ ! -f "package.json" ]; then
    echo "âŒ ì˜¤ë¥˜: package.jsonì´ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í„°ë¦¬ì—ì„œ ì‹¤í–‰í•´ì£¼ì„¸ìš”."
    exit 1
fi

# 1. OpenAI ê´€ë ¨ íŒ¨í‚¤ì§€ ì„¤ì¹˜
echo "ðŸ“¦ AI ê´€ë ¨ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘..."
npm install openai@latest node-cache tiktoken

# 2. AI ì„œë¹„ìŠ¤ ë””ë ‰í„°ë¦¬ ì¤€ë¹„
echo "ðŸ“ AI ì„œë¹„ìŠ¤ ë””ë ‰í„°ë¦¬ êµ¬ì¡° ìƒì„± ì¤‘..."
mkdir -p src/modules/ai/enhanced
mkdir -p src/routes/ai

# 3. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
echo "ðŸ”‘ OpenAI í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì¤‘..."
if ! grep -q "OPENAI_API_KEY" .env; then
    echo "" >> .env
    echo "# OpenAI API ì„¤ì • ($(date)ì— ì¶”ê°€ë¨)" >> .env
    echo "OPENAI_API_KEY=your_openai_api_key_here" >> .env
    echo "OPENAI_MODEL=gpt-4" >> .env
    echo "OPENAI_MAX_TOKENS=4000" >> .env
    echo "OPENAI_TEMPERATURE=0.7" >> .env
    echo "OPENAI_TIMEOUT=30000" >> .env
    echo "" >> .env
    echo "# AI ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§" >> .env
    echo "OPENAI_DAILY_LIMIT=100000" >> .env
    echo "OPENAI_COST_ALERT=50" >> .env
else
    echo "âš ï¸  OpenAI í™˜ê²½ ë³€ìˆ˜ê°€ ì´ë¯¸ ì„¤ì •ë˜ì–´ ìžˆìŠµë‹ˆë‹¤."
fi

# 4. í–¥ìƒëœ AI ì„œë¹„ìŠ¤ í…œí”Œë¦¿ ìƒì„±
echo "ðŸ“„ í–¥ìƒëœ AI ì„œë¹„ìŠ¤ í…œí”Œë¦¿ ìƒì„± ì¤‘..."

cat > src/modules/ai/EnhancedAIService.js << 'EOF'
/**
 * í–¥ìƒëœ AI ì„œë¹„ìŠ¤
 * OpenAI API ì‹¤ì œ í†µí•© ë° ê³ ê¸‰ ê¸°ëŠ¥
 */

import OpenAI from 'openai';
import NodeCache from 'node-cache';
import { DatabaseService } from '../../services/DatabaseService.js';

export class EnhancedAIService {
  constructor() {
    // OpenAI API í‚¤ í™•ì¸
    if (!process.env.OPENAI_API_KEY || process.env.OPENAI_API_KEY === 'your_openai_api_key_here') {
      console.warn('âš ï¸  OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. AI ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.');
      this.openai = null;
    } else {
      this.openai = new OpenAI({
        apiKey: process.env.OPENAI_API_KEY
      });
    }
    
    this.cache = new NodeCache({ stdTTL: 3600 }); // 1ì‹œê°„ ìºì‹œ
    this.db = new DatabaseService();
    
    this.usage = {
      totalTokens: 0,
      totalCost: 0,
      requestCount: 0
    };
  }

  /**
   * ì‹¤ì œ OpenAI APIë¥¼ ì‚¬ìš©í•œ ì½”ë“œ ìƒì„±
   */
  async generateCode(prompt, options = {}) {
    if (!this.openai) {
      return this.generateMockCode(prompt, options);
    }

    try {
      const {
        language = 'javascript',
        framework = '',
        style = 'modern'
      } = options;

      // ìºì‹œ í™•ì¸
      const cacheKey = this.generateCacheKey('code', { prompt, language, framework });
      const cached = this.cache.get(cacheKey);
      if (cached) return cached;

      // OpenAI API í˜¸ì¶œ
      const response = await this.openai.chat.completions.create({
        model: process.env.OPENAI_MODEL || 'gpt-4',
        messages: [
          {
            role: 'system',
            content: `ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ${language} ê°œë°œìžìž…ë‹ˆë‹¤. ê³ í’ˆì§ˆì˜ ì½”ë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.`
          },
          {
            role: 'user',
            content: `${prompt}\n\nì–¸ì–´: ${language}\ní”„ë ˆìž„ì›Œí¬: ${framework}\nìŠ¤íƒ€ì¼: ${style}`
          }
        ],
        temperature: 0.2,
        max_tokens: parseInt(process.env.OPENAI_MAX_TOKENS || '4000')
      });

      const result = {
        code: response.choices[0].message.content,
        language,
        framework,
        generated_at: new Date().toISOString(),
        tokens_used: response.usage.total_tokens
      };

      // ìºì‹œ ë° ì‚¬ìš©ëŸ‰ ì €ìž¥
      this.cache.set(cacheKey, result);
      await this.trackUsage('code_generation', response.usage);

      return result;

    } catch (error) {
      console.error('OpenAI ì½”ë“œ ìƒì„± ì˜¤ë¥˜:', error);
      return this.generateMockCode(prompt, options);
    }
  }

  /**
   * ì‹¤ì œ OpenAI APIë¥¼ ì‚¬ìš©í•œ ì½”ë“œ ë¦¬ë·°
   */
  async reviewCode(code, options = {}) {
    if (!this.openai) {
      return this.generateMockReview(code, options);
    }

    try {
      const { language = 'javascript' } = options;

      const response = await this.openai.chat.completions.create({
        model: process.env.OPENAI_MODEL || 'gpt-4',
        messages: [
          {
            role: 'system',
            content: 'ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ìž…ë‹ˆë‹¤. ì½”ë“œë¥¼ ì „ë¬¸ì ìœ¼ë¡œ ë¦¬ë·°í•´ì£¼ì„¸ìš”.'
          },
          {
            role: 'user',
            content: `ë‹¤ìŒ ${language} ì½”ë“œë¥¼ ë¦¬ë·°í•´ì£¼ì„¸ìš”:\n\n${code}`
          }
        ],
        temperature: 0.1,
        max_tokens: 2000
      });

      const result = {
        review: response.choices[0].message.content,
        language,
        reviewed_at: new Date().toISOString(),
        tokens_used: response.usage.total_tokens
      };

      await this.trackUsage('code_review', response.usage);
      return result;

    } catch (error) {
      console.error('OpenAI ì½”ë“œ ë¦¬ë·° ì˜¤ë¥˜:', error);
      return this.generateMockReview(code, options);
    }
  }

  /**
   * AI ì–´ì‹œìŠ¤í„´íŠ¸ ì±„íŒ…
   */
  async chatWithAssistant(message, context = {}) {
    if (!this.openai) {
      return {
        response: 'ì£„ì†¡í•©ë‹ˆë‹¤. AI ì–´ì‹œìŠ¤í„´íŠ¸ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.',
        mock: true
      };
    }

    try {
      const response = await this.openai.chat.completions.create({
        model: process.env.OPENAI_MODEL || 'gpt-4',
        messages: [
          {
            role: 'system',
            content: 'ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ê°œë°œ ì–´ì‹œìŠ¤í„´íŠ¸ìž…ë‹ˆë‹¤. ê°œë°œ ê´€ë ¨ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.'
          },
          {
            role: 'user',
            content: message
          }
        ],
        temperature: 0.7,
        max_tokens: 1500
      });

      const result = {
        response: response.choices[0].message.content,
        timestamp: new Date().toISOString(),
        tokens_used: response.usage.total_tokens
      };

      await this.trackUsage('chat_assistant', response.usage);
      return result;

    } catch (error) {
      console.error('AI ì–´ì‹œìŠ¤í„´íŠ¸ ì˜¤ë¥˜:', error);
      return {
        response: 'ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ìž ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.',
        error: true
      };
    }
  }

  /**
   * ì‚¬ìš©ëŸ‰ ì¶”ì 
   */
  async trackUsage(operation, usage) {
    this.usage.totalTokens += usage.total_tokens;
    this.usage.requestCount++;
    
    // GPT-4 ìš”ê¸ˆ ê³„ì‚° (ëŒ€ëžµì )
    const cost = (usage.prompt_tokens * 0.03 + usage.completion_tokens * 0.06) / 1000;
    this.usage.totalCost += cost;

    console.log(`ðŸ¤– AI ì‚¬ìš©ëŸ‰: ${operation}, í† í°: ${usage.total_tokens}, ë¹„ìš©: $${cost.toFixed(4)}`);

    // ë¹„ìš© ì•Œë¦¼
    const costAlert = parseInt(process.env.OPENAI_COST_ALERT || '50');
    if (this.usage.totalCost > costAlert) {
      console.warn(`âš ï¸ OpenAI ì‚¬ìš© ë¹„ìš©ì´ $${this.usage.totalCost.toFixed(2)}ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤!`);
    }
  }

  /**
   * Mock ì½”ë“œ ìƒì„± (API í‚¤ê°€ ì—†ì„ ë•Œ)
   */
  generateMockCode(prompt, options) {
    const { language = 'javascript' } = options;
    
    return {
      code: `// AIê°€ ìƒì„±í•œ ${language} ì½”ë“œ (Mock)\n// í”„ë¡¬í”„íŠ¸: ${prompt}\n\nfunction generatedFunction() {\n  // TODO: ì‹¤ì œ OpenAI API í‚¤ë¥¼ ì„¤ì •í•˜ë©´ ì‹¤ì œ ì½”ë“œê°€ ìƒì„±ë©ë‹ˆë‹¤\n  console.log('AI ì½”ë“œ ìƒì„± ê¸°ëŠ¥ í™œì„±í™” í•„ìš”');\n}`,
      language,
      generated_at: new Date().toISOString(),
      mock: true
    };
  }

  /**
   * Mock ì½”ë“œ ë¦¬ë·° (API í‚¤ê°€ ì—†ì„ ë•Œ)
   */
  generateMockReview(code, options) {
    return {
      review: 'ì‹¤ì œ OpenAI API í‚¤ë¥¼ ì„¤ì •í•˜ë©´ ì „ë¬¸ì ì¸ ì½”ë“œ ë¦¬ë·°ë¥¼ ë°›ì„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n\nê¸°ë³¸ ë¶„ì„:\n- ì½”ë“œ ê¸¸ì´: ' + code.length + 'ìž\n- ê¶Œìž¥ì‚¬í•­: OpenAI API í‚¤ ì„¤ì • í›„ ìž¬ì‹œë„',
      language: options.language || 'javascript',
      reviewed_at: new Date().toISOString(),
      mock: true
    };
  }

  /**
   * ìºì‹œ í‚¤ ìƒì„±
   */
  generateCacheKey(type, params) {
    return `${type}_${JSON.stringify(params)}`;
  }

  /**
   * ì‚¬ìš©ëŸ‰ í†µê³„
   */
  getUsageStats() {
    return {
      ...this.usage,
      averageCostPerRequest: this.usage.requestCount > 0 
        ? this.usage.totalCost / this.usage.requestCount 
        : 0,
      apiKeyConfigured: !!this.openai
    };
  }
}
EOF

# 5. AI ì±„íŒ… ë¼ìš°í„° ìƒì„±
cat > src/routes/ai-chat.js << 'EOF'
/**
 * AI ì–´ì‹œìŠ¤í„´íŠ¸ ì±„íŒ… API ë¼ìš°í„°
 */

import express from 'express';
import { EnhancedAIService } from '../modules/ai/EnhancedAIService.js';

const router = express.Router();
const aiService = new EnhancedAIService();

/**
 * POST /api/v1/ai-chat/message
 * AI ì–´ì‹œìŠ¤í„´íŠ¸ì™€ ì±„íŒ…
 */
router.post('/message', async (req, res) => {
  try {
    const { message, context } = req.body;
    
    if (!message) {
      return res.status(400).json({
        success: false,
        error: 'ë©”ì‹œì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.'
      });
    }

    const response = await aiService.chatWithAssistant(message, context);
    
    res.json({
      success: true,
      data: response
    });
  } catch (error) {
    console.error('AI ì±„íŒ… ì˜¤ë¥˜:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

/**
 * GET /api/v1/ai-chat/usage
 * AI ì‚¬ìš©ëŸ‰ í†µê³„
 */
router.get('/usage', (req, res) => {
  try {
    const stats = aiService.getUsageStats();
    
    res.json({
      success: true,
      data: stats
    });
  } catch (error) {
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

export default router;
EOF

# 6. ê¸°ì¡´ AI ì„œë¹„ìŠ¤ ì—…ê·¸ë ˆì´ë“œ ê°€ì´ë“œ ìƒì„±
cat > src/modules/ai/UPGRADE_GUIDE.md << 'EOF'
# AI ì„œë¹„ìŠ¤ ì—…ê·¸ë ˆì´ë“œ ê°€ì´ë“œ

## ê¸°ì¡´ ì„œë¹„ìŠ¤ ì—…ê·¸ë ˆì´ë“œ

### 1. AIService.js ì—…ê·¸ë ˆì´ë“œ
ê¸°ì¡´ `AIService.js`ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ìˆ˜ì •:

```javascript
// ê¸°ì¡´ ì½”ë“œ ëŒ€ì‹  EnhancedAIService ì‚¬ìš©
import { EnhancedAIService } from './EnhancedAIService.js';

export class AIService extends EnhancedAIService {
  // ê¸°ì¡´ ë©”ì„œë“œë“¤ì„ ìœ ì§€í•˜ë©´ì„œ ìƒˆë¡œìš´ ê¸°ëŠ¥ ì¶”ê°€
}
```

### 2. CodeGenerator.js ì—…ê·¸ë ˆì´ë“œ
```javascript
// generateCode ë©”ì„œë“œ ìˆ˜ì •
async generateCode(prompt, options = {}) {
  // ì‹¤ì œ AI ê¸°ëŠ¥ ì‚¬ìš©
  return await this.aiService.generateCode(prompt, options);
}
```

### 3. CodeReviewService.js ì—…ê·¸ë ˆì´ë“œ
```javascript
// performAIAnalysis ë©”ì„œë“œ ìˆ˜ì •
async performAIAnalysis(codeContent, filePath) {
  const aiReview = await this.aiService.reviewCode(codeContent, {
    language: this.detectLanguage(filePath)
  });
  
  return {
    score: 85, // AI ì‘ë‹µì—ì„œ ì ìˆ˜ ì¶”ì¶œ
    insights: [aiReview.review],
    improvements: []
  };
}
```

## ë‹¤ìŒ ë‹¨ê³„

1. OpenAI API í‚¤ ì„¤ì •
2. ê¸°ì¡´ ì„œë¹„ìŠ¤ ì—…ê·¸ë ˆì´ë“œ
3. ìƒˆë¡œìš´ ì±„íŒ… ë¼ìš°í„° í†µí•©
4. í…ŒìŠ¤íŠ¸ ì‹¤í–‰
EOF

echo ""
echo "âœ… AI ì‹œìŠ¤í…œ ì‹¤ì œ í†µí•© ì¤€ë¹„ ì™„ë£Œ!"
echo ""
echo "ðŸ”‘ ì¤‘ìš”: OpenAI API í‚¤ ì„¤ì •"
echo "1. https://platform.openai.com/api-keys ì—ì„œ API í‚¤ ìƒì„±"
echo "2. .env íŒŒì¼ì—ì„œ OPENAI_API_KEY=your_actual_key_here ë¡œ ì„¤ì •"
echo ""
echo "ðŸ“ ë‹¤ìŒ ë‹¨ê³„:"
echo "1. OpenAI API í‚¤ë¥¼ ì‹¤ì œ í‚¤ë¡œ êµì²´"
echo "2. ê¸°ì¡´ AI ì„œë¹„ìŠ¤ë“¤ì„ EnhancedAIServiceë¡œ ì—…ê·¸ë ˆì´ë“œ"
echo "3. AI ì±„íŒ… ë¼ìš°í„°ë¥¼ index.jsì— ì¶”ê°€"
echo ""
echo "ðŸ”§ ì°¸ê³  ë¬¸ì„œ:"
echo "- docs/ai-integration/AI_INTEGRATION_GUIDE.md"
echo "- src/modules/ai/UPGRADE_GUIDE.md"
echo ""
echo "ðŸš€ ë°”ë¡œ ì‹œìž‘í•˜ë ¤ë©´:"
echo "code .env  # API í‚¤ ì„¤ì •"
echo "code src/modules/ai/EnhancedAIService.js  # AI ì„œë¹„ìŠ¤ í™•ì¸"
